---
title: "Tidymodels"
output: html_notebook
---

# executer "Data_management.rmd" first

```{r}
library(tidymodels)
library(tidyverse)

```


# Selection de variables 
# Selon les matrices de corrélation : supprimer -nbv, -etatp, -locp
```{r}
glimpse(gravity)
dim(gravity)


gravity_tidymodel <- gravity %>%
  select(-nbv, -etatp,-locp) %>% 
   select(grav_or_not, sexe, age, secu_or_not,trajet, secu_level, lat, long)

# gravity <- total_19%>% 
#   filter(!is.na(grav)) %>% 
#   filter(grepl("^35", dep)) %>% 
#   mutate(grav_or_not = 
#         case_when(
#         grav == "2" | grav == "3" ~ "1",
#         TRUE ~ "0"
#         )
#   ) %>% 
#   mutate(age = 2019-an_nais) %>% 
#   mutate(grav_or_not = as.factor(grav_or_not),
#          sexe = as.factor(sexe),
#          trajet = as.factor(trajet),
#          secu_or_not = as.factor(secu_or_not),
#          secu_level = as.factor(secu_level)
#          ) %>%
#   select(grav_or_not, sexe, age, secu_or_not,trajet, secu_level, lat, long)
# 
# gravity %>% group_by(grav_or_not) %>% 
#   summarise(n=n())
#   
# glimpse(gravity)
# colnames(total_19)



```



# il faudrait faire quelques ggplot
```{r}

```


# Définition de trainning set et test set
```{r}

set.seed(1234)


ames_split <- initial_split(gravity_tidymodel, prob = 0.80)
ames_train <- training(ames_split)
ames_test <- testing(ames_split)
# ames_test_small <- ames_test %>% head(5)

dim(ames_train)
dim(ames_test)
colnames(ames_train)

```

# Définition de recette basique et visualisation de design matrice
```{r}
ames_rec <-
  recipe(grav_or_not ~ ., data = ames_train) %>%
#   step_other(UniqueCarrier, threshold = 0.01) %>%
#   # step_mutate(DepDelay = log(1-min(DepDelay)+DepDelay))%>%
#   step_mutate(DepDelay=log(1-min(DepDelay)+DepDelay))%>%
  step_dummy(all_nominal(), -grav_or_not)
  # %>%
#   step_interact( ~ DepDelay:starts_with("UniqueCarrier_") ) %>%
#   step_ns(DepDelay, deg_free = 20)

# ces lignes de code dessous pour visualiser la design matrice
ames_rec_prepped <- prep(ames_rec) # si je met pas de parametre data, il va prendre le meme que la recette

# hf_train_prepped <-  bake(ames_rec_prepped, new_data = NULL) # cest notre matrice_design
# hf_test_prepped <- bake(ames_rec_prepped, new_data = ames_test)

matrice_design <- bake(ames_rec_prepped, new_data = NULL)
matrice_design

```


## Definition des modèles sans tuning
# https://parsnip.tidymodels.org/reference/
# https://www.tmwr.org/workflow-sets.html

# Log
```{r}

log_model <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")


log_wflow <-
  workflow() %>%
  add_model(log_model) %>%
  add_recipe(ames_rec)
  
log_fit <- fit(log_wflow, ames_train)

log_pred <- ames_test %>%
  select(grav_or_not) %>%
  bind_cols(predict(log_fit, ames_test, type='prob')) 
# %>%
#   bind_cols(predict(lm_fit, ames_test, type = "pred_int")) # pour RandomForest il ny a pas de pred_int

log_pred

```

# LASSO/Ridge regression
# https://juliasilge.com/blog/lasso-the-office/

```{r}

```


# Ramdon forest
```{r}
  

library(ranger)
rf_model <-
  rand_forest(trees = 10) %>%
  set_engine("ranger") %>%
  set_mode("classification")

rf_wflow <-
  workflow() %>%
  add_recipe(ames_rec) %>% 
  add_model(rf_model)

# rf_fit et rf_pred n'est pas forcement necessaire à cette étape. on peut directement passer a la validation
rf_fit <- 
  fit(rf_wflow, ames_train)

rf_pred <- ames_test %>%
  select(grav_or_not) %>%
  bind_cols(predict(rf_fit, ames_test, type='prob')) 
   
rf_pred

```

# General Interface for Boosted Trees
```{r}
library(xgboost)

xgboost_model <- 
  parsnip::boost_tree(
    mode = "classification",
    trees = 10,
    sample_size =0.1
    # min_n = tune(),
    # tree_depth = tune(),
    # learn_rate = tune(),
    # loss_reduction = tune()
  ) %>%
    set_engine("xgboost", objective = "reg:squarederror")

xgboost_wf <- 
  workflows::workflow() %>%
  add_model(xgboost_model) %>%
  add_recipe(ames_rec)

bt_fit <-
  fit(xgboost_wf, ames_train)

bt_pred <- ames_test %>%
  select(grav_or_not) %>%
  bind_cols(predict(bt_fit, ames_test, type='prob'))

bt_pred

```




## Evaluation d'un modèle. En réalité on va utiliser tidymodels Workflows collection (plus tard)
# Validation croisée
# Combine metric functions :  https://yardstick.tidymodels.org/
# Comparing models with resampling
# https://www.tmwr.org/compare.html

# Create a Collection of recipes



```{r}
ames_resampling <- vfold_cv(ames_train, v = 3,)
keep_pred <- control_resamples(save_pred = TRUE, save_workflow = TRUE)

interaction_rec <- 
  ames_rec %>% 
  step_interact( ~ starts_with("secu_or_not_"):starts_with("trajet_")) 


```

## Create a Collection of tidymodels Workflows
# https://workflowsets.tidymodels.org/


## Tunning
# Trois cas pour faire la tuning, la difficulté est de recupérer les paramètres tuning depuis un workflow_map (car show_best ne fonctionne qu'avec un tuning_grid (ie un model et un recette))

# Tuning le model
```{r}

xgboost_model_tune <- 
  parsnip::boost_tree(
    mode = "classification",
    trees = 10,
    min_n = tune(),
    tree_depth = tune(),
    learn_rate = tune(),
    loss_reduction = tune()
  ) %>%
  set_engine("xgboost", objective = "reg:squarederror")

mars_spec_tune <- 
   mars(prod_degree = tune()) %>%  #<- use GCV to choose terms
   set_engine("earth") %>% 
   set_mode("classification")

svm_r_spec_tune <- 
   svm_rbf(cost = tune(), rbf_sigma = tune()) %>% 
   set_engine("kernlab") %>% 
   set_mode("classification")

svm_p_spec_tune <- 
   svm_poly(cost = tune(), degree = tune()) %>% 
   set_engine("kernlab") %>% 
   set_mode("classification")

library(rules)
cubist_spec_tune <- 
   cubist_rules(committees = tune(), neighbors = tune()) %>% 
   set_engine("Cubist")

knn_spec_tune <- 
   nearest_neighbor(neighbors = tune(), dist_power = tune(), weight_func = tune()) %>% 
   set_engine("kknn") %>% 
   set_mode("classification")

cart_spec_tune <- 
   decision_tree(cost_complexity = tune(), min_n = tune()) %>% 
   set_engine("rpart") %>% 
   set_mode("classification")


library(baguette)
tidymodels_prefer()
bag_cart_spec <- 
   bag_tree() %>% 
   set_engine("rpart", times = 50L) %>% 
   set_mode("classification")


nnet_spec_tune <- 
   mlp(hidden_units = tune(), penalty = tune(), epochs = tune()) %>% 
   set_engine("nnet", MaxNWts = 2600) %>% 
   set_mode("classification")

nnet_param <- 
   nnet_spec_tune %>% 
   parameters() %>% 
   update(hidden_units = hidden_units(c(1, 27)))




```



# Tuning le recette

```{r}

spline_rec_tune <- 
  interaction_rec %>% 
  step_ns(lat, long, deg_free = tune())

parameters(spline_rec_tune)


```


# Tuning les modèles mais ne pas tuning la recette. Puis pousser directement la meilleure modèle dans workflow pour prédire. https://github.com/tidymodels/workflowsets/blob/main/vignettes/articles/tuning-and-comparing-models.Rmd



```{r}


chi_models <- 
   workflow_set(
      preproc = list( basic = ames_rec, 
                      #interact = interaction_rec,
                      spline_tune = spline_rec_tune
                      #splines = spline_rec
                      ),
      models =list(log = log_model,
                    rf=rf_model,
                   bt =xgboost_model_tune,
                   SVM_radial = svm_r_spec_tune,
                   SVM_poly = svm_p_spec_tune,
                   KNN = knn_spec_tune,
                   neural_network = nnet_spec_tune
                  ),
      cross = TRUE
   )
chi_models



chi_models <- 
  chi_models %>% 
  workflow_map(#"fit_resamples", 
               # Options to `workflow_map()`: 
               seed = 1101, verbose = TRUE,
               # Options to `fit_resamples()`: 
               resamples = ames_resampling, 
               grid = 20,
               metrics = metric_set(accuracy, roc_auc, pr_auc), 
               control = keep_pred)


```

# Ranking, trouver le meilleur modèle selon metric
```{r}
rank_results(chi_models, rank_metric = "roc_auc")  # splines_neural_network est classe en 1er, donc renseigner dans loption de best_results

# DF <- rank_results(chi_models, rank_metric = "roc_auc") 
# write.table(DF, "C:/feigao/Fei_ENSAE_Formation/R preparation/PFE/PFE_Datascientist_CEPE/df.csv")

# autoplot(chi_models, metric = "roc_auc")
autoplot(
   chi_models,
   rank_metric = "roc_auc",  # <- how to order models
   metric = "roc_auc",       # <- which metric to visualize
   select_best = TRUE     # <- one point per workflow
)

rank_results(chi_models, rank_metric = "roc_auc") %>% group_by(model,wflow_id) %>% summarise(n=n())
```

# Pousser le meilleur modèle dans le workflow puis faire la prédiction avec

# Pousser le modèle NN puis faire la prédiction
```{r}
################### Pousser neural_network ###########################
best_results <- 
   chi_models %>% 
   pull_workflow_set_result("spline_tune_neural_network") %>% 
   select_best(metric = "accuracy")

best_results


neural_network_test_results <- 
   chi_models %>% 
   pull_workflow("spline_tune_neural_network") %>% 
   finalize_workflow(best_results) %>% 
   last_fit(split = ames_split)

neural_network_test_results %>% 
   collect_predictions()


```

## TO DO LIST
More and more models
# https://www.tmwr.org/workflow-sets.html
lasso
# https://juliasilge.com/blog/lasso-the-office/ 

## essaie d'inclure tune_grid dans workflow_map (seulement tuning le modèle, sans tuning la recette)
# https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/

# (https://workflowsets.tidymodels.org/reference/workflow_map.html)

# (https://tune.tidymodels.org/reference/tune_grid.html)
